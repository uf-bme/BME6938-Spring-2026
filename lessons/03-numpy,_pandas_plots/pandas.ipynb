{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7c4675",
   "metadata": {},
   "source": [
    "# Introduction to Pandas üêº\n",
    "## Data Analysis Made Easy\n",
    "\n",
    "**Duration: 50 minutes**  \n",
    "**Target Audience: Beginners with little to no pandas experience**\n",
    "\n",
    "---\n",
    "\n",
    "### What We'll Learn Today:\n",
    "1. **What is Pandas?** (5 minutes)\n",
    "2. **Setting Up & First Steps** (5 minutes)\n",
    "3. **Series: The Building Block** (10 minutes)\n",
    "4. **DataFrames: Your New Best Friend** (15 minutes)\n",
    "5. **Data Exploration & Basic Operations** (10 minutes)\n",
    "6. **Hands-on Practice** (5 minutes)\n",
    "\n",
    "---\n",
    "\n",
    "> **üí° Tip:** Run each code cell as we go through the lesson. Press `Shift + Enter` to execute a cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6dea72",
   "metadata": {},
   "source": [
    "## 1. What is Pandas? ü§î\n",
    "\n",
    "**Pandas** (Python Data Analysis Library) is like a Swiss Army knife for data analysis. Think of it as Excel on steroids!\n",
    "\n",
    "### Why Pandas?\n",
    "- üìä **Easy data manipulation**: Clean, transform, and analyze data effortlessly\n",
    "- üìà **Handles multiple data types**: Numbers, text, dates, and more\n",
    "- üîó **Integrates beautifully**: Works seamlessly with other Python libraries\n",
    "- üöÄ **Performance**: Built on NumPy for speed\n",
    "\n",
    "### Real-world Applications:\n",
    "- üè• **Healthcare**: Analyzing patient data and treatment outcomes\n",
    "- üí∞ **Finance**: Stock market analysis and risk assessment\n",
    "- üõí **E-commerce**: Customer behavior and sales trends\n",
    "- üå± **Research**: Scientific data analysis and visualization\n",
    "\n",
    "---\n",
    "**Think of pandas as your data assistant that never gets tired of organizing spreadsheets!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d040879",
   "metadata": {},
   "source": [
    "## 2. Setting Up & First Steps üöÄ\n",
    "\n",
    "Let's start our pandas journey! First, we need to import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas (the standard convention is to use 'pd' as an alias)\n",
    "import pandas as pd\n",
    "import numpy as np  # We'll use this for some examples\n",
    "\n",
    "# Let's check which version of pandas we're using\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(\"üéâ Pandas is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3de374",
   "metadata": {},
   "source": [
    "## 3. Series: The Building Block üß±\n",
    "\n",
    "A **Series** is like a single column in a spreadsheet. It's a one-dimensional array that can hold any data type.\n",
    "\n",
    "### Think of it as:\n",
    "- A list with superpowers\n",
    "- A single column from Excel\n",
    "- A 1D array with labels (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our first Series - Student scores\n",
    "scores = pd.Series([85, 92, 78, 96, 88])\n",
    "print(\"Student Scores:\")\n",
    "print(scores)\n",
    "print(f\"\\nType: {type(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series with custom labels (index)\n",
    "student_names = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n",
    "named_scores = pd.Series([85, 92, 78, 96, 88], index=student_names)\n",
    "\n",
    "print(\"Scores with Student Names:\")\n",
    "print(named_scores)\n",
    "print(f\"\\nAlice's score: {named_scores['Alice']}\")\n",
    "print(f\"Highest score: {named_scores.max()}\")\n",
    "print(f\"Average score: {named_scores.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147ca20",
   "metadata": {},
   "source": [
    "### üîç Quick Exercise: Try it yourself!\n",
    "Create a Series with the temperatures for a week. Use the days of the week as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389be567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Create a temperature series for the week\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "temperatures = [72, 75, 78, 74, 71, 69, 73]  # Temperatures in Fahrenheit\n",
    "\n",
    "weekly_temps = pd.Series(temperatures, index=days)\n",
    "print(\"Weekly Temperatures:\")\n",
    "print(weekly_temps)\n",
    "print(f\"\\nWarmest day: {weekly_temps.idxmax()} ({weekly_temps.max()}¬∞F)\")\n",
    "print(f\"Coolest day: {weekly_temps.idxmin()} ({weekly_temps.min()}¬∞F)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a0a21",
   "metadata": {},
   "source": [
    "## 4. DataFrames: Your New Best Friend üìä\n",
    "\n",
    "A **DataFrame** is like a complete spreadsheet - it has multiple columns and rows. Think of it as multiple Series combined together!\n",
    "\n",
    "### Analogy:\n",
    "- üìã **Series** = Single column in Excel\n",
    "- üìä **DataFrame** = Complete Excel worksheet with multiple columns\n",
    "\n",
    "### Key Features:\n",
    "- 2-dimensional (rows and columns)\n",
    "- Each column can have different data types\n",
    "- Built-in indexing and labeling\n",
    "- Perfect for real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our first DataFrame - Student information\n",
    "student_data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [20, 21, 19, 22, 20],\n",
    "    'Grade': ['A', 'B+', 'B', 'A+', 'A-'],\n",
    "    'Score': [85, 92, 78, 96, 88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(student_data)\n",
    "print(\"Student DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore our DataFrame\n",
    "print(\"DataFrame Shape (rows, columns):\", df.shape)\n",
    "print(\"\\nColumn Names:\", df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d494561",
   "metadata": {},
   "source": [
    "### Selecting Data from DataFrames\n",
    "\n",
    "Just like in Excel, we often want to look at specific columns or rows. Pandas makes this super easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4035863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column (returns a Series)\n",
    "print(\"Just the names:\")\n",
    "print(df['Name'])\n",
    "print(f\"\\nType: {type(df['Name'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "\n",
    "# Selecting multiple columns (returns a DataFrame)\n",
    "print(\"Names and Scores:\")\n",
    "print(df[['Name', 'Score']])\n",
    "print(f\"\\nType: {type(df[['Name', 'Score']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cfff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data (like using filters in Excel)\n",
    "print(\"Students with score >= 90:\")\n",
    "high_scorers = df[df['Score'] >= 90]\n",
    "print(high_scorers)\n",
    "\n",
    "print(\"\\nStudents aged 20:\")\n",
    "age_20 = df[df['Age'] == 20]\n",
    "print(age_20[['Name', 'Age', 'Score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f515fb",
   "metadata": {},
   "source": [
    "### Adding New Columns\n",
    "\n",
    "Just like adding a new column in Excel, we can easily add new data to our DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['Pass'] = df['Score'] >= 80  # Boolean column: True if score >= 80\n",
    "df['Score_Category'] = df['Score'].apply(lambda x: 'Excellent' if x >= 90 \n",
    "                                        else 'Good' if x >= 80 \n",
    "                                        else 'Needs Improvement')\n",
    "\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cf6d1",
   "metadata": {},
   "source": [
    "## 5. Data Exploration & Basic Operations üîç\n",
    "\n",
    "Now let's learn some essential operations that you'll use all the time in data analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics - like having a built-in calculator!\n",
    "print(\"üìä BASIC STATISTICS\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Average score: {df['Score'].mean():.1f}\")\n",
    "print(f\"Median score: {df['Score'].median()}\")\n",
    "print(f\"Highest score: {df['Score'].max()}\")\n",
    "print(f\"Lowest score: {df['Score'].min()}\")\n",
    "print(f\"Score range: {df['Score'].max() - df['Score'].min()}\")\n",
    "\n",
    "print(\"\\nüìà SUMMARY STATISTICS\")\n",
    "print(\"=\"*30)\n",
    "print(df['Score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data (like sorting in Excel)\n",
    "print(\"üìã STUDENTS SORTED BY SCORE (Highest first):\")\n",
    "print(df.sort_values('Score', ascending=False)[['Name', 'Score', 'Grade']])\n",
    "\n",
    "print(\"\\nüìã STUDENTS SORTED BY NAME (Alphabetical):\")\n",
    "print(df.sort_values('Name')[['Name', 'Age', 'Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data (like pivot tables in Excel)\n",
    "print(\"üìä PERFORMANCE BY AGE:\")\n",
    "age_groups = df.groupby('Age')['Score'].agg(['mean', 'count'])\n",
    "print(age_groups)\n",
    "\n",
    "print(\"\\nüìä GRADE DISTRIBUTION:\")\n",
    "grade_counts = df['Grade'].value_counts()\n",
    "print(grade_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc0419",
   "metadata": {},
   "source": [
    "### Working with Real Data: Reading Files\n",
    "\n",
    "In the real world, data often comes from files. Let's create and read a CSV file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our DataFrame to a CSV file\n",
    "df.to_csv('students.csv', index=False)\n",
    "print(\"‚úÖ Saved students.csv\")\n",
    "\n",
    "# Read it back\n",
    "df_from_file = pd.read_csv('students.csv')\n",
    "print(\"\\nüìÇ Data read from CSV file:\")\n",
    "print(df_from_file)\n",
    "\n",
    "# Check if they're the same\n",
    "print(f\"\\nAre they identical? {df.equals(df_from_file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54c428",
   "metadata": {},
   "source": [
    "## 6. Hands-on Practice Challenge! üéØ\n",
    "\n",
    "**Scenario:** You're analyzing data for a small coffee shop. Let's create and analyze some sales data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94672534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coffee shop sales data\n",
    "coffee_data = {\n",
    "    'Day': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    'Espresso': [25, 30, 28, 35, 45, 60, 40],\n",
    "    'Latte': [40, 45, 42, 50, 65, 80, 55],\n",
    "    'Cappuccino': [20, 25, 23, 30, 35, 45, 32],\n",
    "    'Temperature': [68, 72, 70, 75, 73, 78, 76]  # Weather temperature\n",
    "}\n",
    "\n",
    "coffee_df = pd.DataFrame(coffee_data)\n",
    "print(\"‚òï COFFEE SHOP SALES DATA\")\n",
    "print(\"=\"*40)\n",
    "print(coffee_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the coffee shop data!\n",
    "\n",
    "# 1. Calculate total daily sales\n",
    "coffee_df['Total_Sales'] = coffee_df['Espresso'] + coffee_df['Latte'] + coffee_df['Cappuccino']\n",
    "\n",
    "# 2. Find the best and worst sales days\n",
    "best_day = coffee_df.loc[coffee_df['Total_Sales'].idxmax(), 'Day']\n",
    "worst_day = coffee_df.loc[coffee_df['Total_Sales'].idxmin(), 'Day']\n",
    "\n",
    "print(f\"üèÜ Best sales day: {best_day} ({coffee_df['Total_Sales'].max()} drinks)\")\n",
    "print(f\"üìâ Worst sales day: {worst_day} ({coffee_df['Total_Sales'].min()} drinks)\")\n",
    "\n",
    "# 3. Most popular drink overall\n",
    "drink_totals = {\n",
    "    'Espresso': coffee_df['Espresso'].sum(),\n",
    "    'Latte': coffee_df['Latte'].sum(),\n",
    "    'Cappuccino': coffee_df['Cappuccino'].sum()\n",
    "}\n",
    "\n",
    "most_popular = max(drink_totals, key=drink_totals.get)\n",
    "print(f\"‚òï Most popular drink: {most_popular} ({drink_totals[most_popular]} total sales)\")\n",
    "\n",
    "# 4. Average sales per day\n",
    "print(f\"üìä Average daily sales: {coffee_df['Total_Sales'].mean():.1f} drinks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"UPDATED DATAFRAME WITH TOTAL SALES:\")\n",
    "print(coffee_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7006c",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: Practice Challenge!\n",
    "\n",
    "**Task:** Answer these questions using pandas operations:\n",
    "\n",
    "1. Which days had sales above the average?\n",
    "2. Is there a relationship between temperature and total sales?\n",
    "3. What percentage of total sales does each drink type represent?\n",
    "\n",
    "Try to solve these in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee49a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE - Try to solve the challenges!\n",
    "\n",
    "# 1. Days with above-average sales\n",
    "avg_sales = coffee_df['Total_Sales'].mean()\n",
    "above_avg_days = coffee_df[coffee_df['Total_Sales'] > avg_sales]['Day'].tolist()\n",
    "print(f\"1Ô∏è‚É£ Days with above-average sales ({avg_sales:.1f}): {above_avg_days}\")\n",
    "\n",
    "# 2. Temperature vs Sales relationship (basic correlation)\n",
    "correlation = coffee_df['Temperature'].corr(coffee_df['Total_Sales'])\n",
    "print(f\"2Ô∏è‚É£ Temperature-Sales correlation: {correlation:.3f}\")\n",
    "print(\"   (1.0 = perfect positive, 0 = no relationship, -1.0 = perfect negative)\")\n",
    "\n",
    "# 3. Drink type percentages\n",
    "total_all_sales = coffee_df[['Espresso', 'Latte', 'Cappuccino']].sum().sum()\n",
    "espresso_pct = (coffee_df['Espresso'].sum() / total_all_sales) * 100\n",
    "latte_pct = (coffee_df['Latte'].sum() / total_all_sales) * 100\n",
    "cappuccino_pct = (coffee_df['Cappuccino'].sum() / total_all_sales) * 100\n",
    "\n",
    "print(f\"3Ô∏è‚É£ Sales by drink type:\")\n",
    "print(f\"   ‚òï Espresso: {espresso_pct:.1f}%\")\n",
    "print(f\"   ‚òï Latte: {latte_pct:.1f}%\")\n",
    "print(f\"   ‚òï Cappuccino: {cappuccino_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250d8be",
   "metadata": {},
   "source": [
    "## üéâ Congratulations! You've Completed Pandas Basics!\n",
    "\n",
    "### What You've Learned Today:\n",
    "‚úÖ **Pandas fundamentals**: Series and DataFrames  \n",
    "‚úÖ **Data creation**: From dictionaries and lists  \n",
    "‚úÖ **Data selection**: Columns, rows, and filtering  \n",
    "‚úÖ **Data manipulation**: Adding columns and transforming data  \n",
    "‚úÖ **Data analysis**: Statistics, sorting, and grouping  \n",
    "‚úÖ **File operations**: Reading and writing CSV files  \n",
    "‚úÖ **Real-world practice**: Coffee shop sales analysis  \n",
    "\n",
    "### Next Steps in Your Pandas Journey:\n",
    "üöÄ **Intermediate Topics:**\n",
    "- Data cleaning and handling missing values\n",
    "- Merging and joining DataFrames\n",
    "- Advanced filtering and querying\n",
    "- Time series analysis\n",
    "- Data visualization with pandas\n",
    "\n",
    "üöÄ **Advanced Topics:**\n",
    "- Performance optimization\n",
    "- Working with large datasets\n",
    "- Integration with other libraries (matplotlib, seaborn, scikit-learn)\n",
    "- Database connections\n",
    "\n",
    "### Key Takeaways:\n",
    "üí° **Remember**: Pandas is like Excel with superpowers  \n",
    "üí° **Practice**: The more you use it, the more natural it becomes  \n",
    "üí° **Explore**: Don't be afraid to try new operations  \n",
    "üí° **Documentation**: `help()` and pandas documentation are your friends  \n",
    "\n",
    "---\n",
    "**Happy Data Analyzing! üêºüìä**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
