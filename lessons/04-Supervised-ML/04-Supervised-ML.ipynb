{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5439235e",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Supervised ML</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h2>Lesson 04</h2></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76f6ad",
   "metadata": {},
   "source": [
    "## **Intro to Supervised Machine Learning**\n",
    "\n",
    "- Understand what supervised learning is and identify its core components: features (inputs), labels (targets), and training data.\n",
    "- Distinguish between classification and regression problems using concrete examples.\n",
    "- Build intuition for decision trees as rule-based models that split data based on feature thresholds.\n",
    "- Train and inspect a simple decision tree using scikit-learn.\n",
    "- Perform train/validation/test splits and interpret basic evaluation results (accuracy, confusion matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef54258",
   "metadata": {},
   "source": [
    "![Machine Learning Types](../../files/machine_learning_types.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f9bfa",
   "metadata": {},
   "source": [
    "### What is Supervised Learning?\n",
    "\n",
    "Supervised learning pairs labeled examples with an algorithm that learns how to map inputs to outputs. Once trained, the model can make predictions on new, unseen data.\n",
    "\n",
    "**Key pieces**\n",
    "\n",
    "- **Dataset**: collection of examples we care about.\n",
    "- **Features (`x`)**: measurable inputs like heart rate, pixels, or number of people on each track.\n",
    "- **Labels (`y`)**: correct answers provided by humans, instruments, or previous experiments.\n",
    "- **Model**: algorithm (decision tree, neural net, etc.) that learns a mapping from features to labels.\n",
    "- **Training**: process of adjusting the model based on data so predictions get closer to true labels.\n",
    "- **Evaluation**: how we score the model’s predictions (e.g., accuracy, mean squared error) to decide if it is good enough or needs improvement.\n",
    "\n",
    "**Classification vs. regression**\n",
    "\n",
    "- Classification predicts categories (e.g., \"tumor is benign or malignant\").\n",
    "- Regression predicts continuous numbers (e.g., blood glucose level in mg/dL).\n",
    "\n",
    "**The feedback loop**\n",
    "Data → Model → Predictions → Compare to Labels → Learn → Repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbed01a",
   "metadata": {},
   "source": [
    "## The Titanic Dataset\n",
    "\n",
    "![Titanic Depiction](../../files/titanic.jpg)\n",
    "\n",
    "**https://www.kaggle.com/datasets/yasserh/titanic-dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863169e",
   "metadata": {},
   "source": [
    "We’ll use the classic **Titanic survival** dataset as a supervised learning problem.\n",
    "\n",
    "We can frame it as supervised learning:\n",
    "\n",
    "- **Inputs/features**: passenger info like class (`pclass`), sex, age, fare, and port of embarkation.\n",
    "- **Output/label**: whether the passenger **survived** (`1`) or **did not survive** (`0`).\n",
    "- This dataset is historical and widely used for teaching ML workflows (it is not a “fairness benchmark”).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd01eb2",
   "metadata": {},
   "source": [
    "### Dataset Preview\n",
    "\n",
    "We’ll load the dataset into a DataFrame and inspect a few rows to understand the columns and missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecf7e7",
   "metadata": {},
   "source": [
    "In the Titanic dataset, we’ll use a small set of human-readable features to predict survival:\n",
    "\n",
    "- `pclass`: passenger class (1st, 2nd, 3rd).\n",
    "- `sex`: passenger sex.\n",
    "- `age`: passenger age (years; may have missing values).\n",
    "- `sibsp`: number of siblings/spouses aboard.\n",
    "- `parch`: number of parents/children aboard.\n",
    "- `fare`: ticket price.\n",
    "- `embarked`: port of embarkation (C/Q/S).\n",
    "\n",
    "The label we want to predict is:\n",
    "\n",
    "- `survived`: `1` if the passenger survived, `0` otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626d2f9",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Copy the prompt below into copilot chat to load the Titanic Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Load the titanic dataset as a dataframe using fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fbc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2fa7111",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Visualize the Titanic Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Create a clean, well-organized Plotly figure with multiple subplots to visualize key metrics from the Titanic dataset. Use a single figure with clearly labeled subplots showing: (1) survival counts, (2) survival rate by sex, (3) survival rate by passenger class, and (4) age distribution split by survival status. Ensure consistent styling across subplots, readable axis labels and titles, and an overall layout suitable for teaching (minimal clutter, clear legends, and appropriate spacing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ad0c10",
   "metadata": {},
   "source": [
    "Decision trees break decisions into small yes/no questions until they reach a conclusion. A tiny (illustrative) tree for Titanic might look like:\n",
    "\n",
    "```\n",
    "Start\n",
    "├─ Is sex == female? → Yes → Predict Survived\n",
    "└─ No\n",
    "   ├─ Is pclass == 1? → Yes → Predict Survived\n",
    "   └─ No → Predict Did Not Survive\n",
    "```\n",
    "\n",
    "Each question corresponds to a split on one feature, and the final prediction is a **leaf node**.\n",
    "\n",
    "**Check-your-understanding**\n",
    "\n",
    "1. Which feature do you think a tree should split on first for Titanic? Why?\n",
    "2. What does a “leaf” represent in a decision tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd5ade",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "A **decision tree** is a supervised machine learning model that makes predictions by asking a sequence of simple **if/then** questions about the input features.\n",
    "\n",
    "## How it works\n",
    "\n",
    "- The tree starts at the **root** (the first question).\n",
    "- Each question applies a **split rule** (e.g., `age < 15`, `sex == \"female\"`).\n",
    "- Splits create **branches** that route examples into smaller groups.\n",
    "- The process continues until reaching a **leaf**, which outputs the final prediction:\n",
    "  - **Classification**: a class label (e.g., survived vs. not survived)\n",
    "  - **Regression**: a numeric value\n",
    "\n",
    "## Why people like decision trees\n",
    "\n",
    "- **Interpretable**: you can explain a prediction by tracing the path of decisions taken.\n",
    "- **Flexible features**: works with both **numeric** and **categorical** inputs.\n",
    "- **Handles nonlinearity**: can capture nonlinear patterns without feature scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cab5c",
   "metadata": {},
   "source": [
    "![Decision Tree](../../files/decision_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b60b31",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Build a Simple Classifier by Hand\n",
    "\n",
    "Before we train a real model, we’ll build a tiny **rule-based baseline**. This mimics the idea of a decision tree split without doing any optimization.\n",
    "\n",
    "**Rules (use these exactly in your code):**\n",
    "\n",
    "1. If `sex == \"female\"`, predict `survived = 1`.\n",
    "2. Else if `age < 15`, predict `survived = 1`.\n",
    "3. Otherwise, predict `survived = 0`.\n",
    "\n",
    "We’ll then compute the accuracy of this heuristic on the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5241f3",
   "metadata": {},
   "source": [
    "#### **Prompt:**\n",
    "\n",
    "Implement and evaluate a simple heuristic baseline for Titanic survival using a dataframe called df. Assume df includes the columns survived, sex, age, and pclass, even if the values are missing or inconsistently formatted. Define a function predict_survival(row) that predicts survival by returning 1 if the passenger is female (case-insensitive), otherwise returning 1 if the passenger’s age can be parsed as a number and is under 15, and returning 0 in all other cases. Convert both age and survived to numeric using pd.to_numeric(..., errors=\"coerce\"), add the predictions to the dataframe as a new column called rule_pred using df.apply(..., axis=1), and compute accuracy only for rows where survived is not missing. Finally, print the accuracy with a clear label and display the first 10 rows showing survived, sex, age, pclass, and rule_pred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaad498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf9a922",
   "metadata": {},
   "source": [
    "This tiny heuristic is a baseline, but it will miss many patterns and interactions in the data. Rather than hand-coding every rule, we let ML algorithms search through many possible splits and automatically build trees with a consistent strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c0d10",
   "metadata": {},
   "source": [
    "### Create a Decision Tree Classifier\n",
    "\n",
    "`scikit-learn` is a widely used Python library that standardizes ML workflows. The pattern is predictable:\n",
    "\n",
    "1. Import the model class.\n",
    "2. Create a model instance (optionally set hyperparameters).\n",
    "3. Fit on training data (learn patterns).\n",
    "4. Predict on data.\n",
    "5. Evaluate with a metric such as accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78580955",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Prepare the Titanic Dataset for Decision Tree Modeling\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Prepare the Titanic dataset for a Decision Tree model using pandas and scikit-learn, assuming a dataframe df already exists. Use the features pclass, sex, age, sibsp, parch, fare, and embarked, with survived as the label. Create a clean modeling dataframe containing only these columns, convert all numeric fields and the label to numeric values using pd.to_numeric(..., errors=\"coerce\"), and apply simple, transparent imputation by filling missing numeric values with the median and missing categorical values with the mode (or \"unknown\" if no mode exists), ensuring categorical strings are lowercased. Drop any rows with missing labels, one-hot encode the categorical variables so they can be used by a decision tree, and then construct the feature matrix X and label vector y. Finally, print the shape of X, display the distribution of the labels, and show the first few rows of X, keeping the code clean and readable for instructional use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10816c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de3d1420",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Train and Visualize a Simple Decision Tree on the Titanic Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Train and visualize a very simple decision tree classifier on the full Titanic dataset to illustrate how decision trees make predictions. Assume a feature matrix `X` and label vector `y` already exist. Fit a `DecisionTreeClassifier` with a fixed `random_state` and a maximum depth of 1, train it on the full dataset, and compute the accuracy on the same data using `accuracy_score`. Print the accuracy with a clear, readable message. Then visualize the trained tree using scikit-learn’s tree plotting utilities, including feature names from `X` and class names labeled as “died (0)” and “survived (1)”. Use filled and rounded nodes, a readable font size, and an appropriate figure size, and add a descriptive title so the visualization is suitable for teaching and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500e53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371ef3d7",
   "metadata": {},
   "source": [
    "### Interpreting Gini and the Diagram\n",
    "\n",
    "- **Gini impurity** measures how mixed the labels are in a node: $G = 1 - \\sum_k p_k^2$, where $p_k$ is the fraction of samples from class $k$. A pure node (all `0` or all `1`) has $G = 0$.\n",
    "- Each box shows: the split rule, the impurity (`gini`), how many samples reach that node (`samples`), the class counts (`value`), and the predicted class (`class`).\n",
    "- Reading the tree top to bottom mirrors the decision process: start at the root question, follow the branch that matches a passenger’s features, and stop at a leaf to see the final prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a66c58",
   "metadata": {},
   "source": [
    "**Why not celebrate yet?** Training and evaluating on the same data can hide overfitting. A deep tree can memorize every row (100% accuracy) but fail on new scenarios. To know how a model will generalize, we need to hold out data the model never sees during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4fa34",
   "metadata": {},
   "source": [
    "### Train / Validation / Test Splits\n",
    "\n",
    "- **Training set**: used to learn the model parameters.\n",
    "- **Validation set**: used to tune choices like tree depth or learning rate without touching the test set.\n",
    "- **Test set**: only used once, at the end, to estimate performance on truly unseen data.\n",
    "\n",
    "A common recipe is 70% train, 15% validation, 15% test (ratios vary). Guard against **data leakage**, which happens when information from the validation or test set sneaks into training—this makes the model look better than it really is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c7c0b",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../../files/train_val_test_split.webp\" alt=\"Train/Validation/Test Split Diagram\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127ef6e",
   "metadata": {},
   "source": [
    "---\n",
    "# Golden Rule of Supervised ML:\n",
    "\n",
    "### **The test data cannot influence the training phase in any way!**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0036d55",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Train/Validation/Test Split\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Split the prepared feature matrix X and label vector y into training, validation, and test sets using scikit-learn. First, perform a stratified train–test split to reserve 30% of the data for temporary holdout, using a fixed random_state for reproducibility. Then split this temporary set evenly into validation and test sets, again using stratification to preserve class balance. Finally, print the number of rows in the training, validation, and test sets with clear, readable messages suitable for teaching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03917b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758aeae2",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Train and Evaluate a Decision Tree Model\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Train and evaluate a small decision tree model on the Titanic dataset using predefined training, validation, and test splits. Assume X_train, X_val, X_test, y_train, y_val, and y_test already exist. Create a DecisionTreeClassifier with a fixed random_state and a limited maximum depth (such as 3), fit it on the training data, and compute accuracy on the training, validation, and test sets using accuracy_score. Finally, summarize the results in a small pandas DataFrame with one row per data split and a corresponding accuracy value, keeping the output clear and suitable for instructional purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bee850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18f6919d",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Visualize Decision Tree Performance and Feature Importance\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Visualize the performance of a trained decision tree classifier on the Titanic dataset using the test split. Assume a fitted model `tree_model` and the test data `X_test` and `y_test` already exist. First, generate predictions on the test set and display a confusion matrix using scikit-learn with clearly labeled classes (“died (0)” and “survived (1)”), a blue color map, integer counts, and a descriptive title. Then compute the model’s feature importances, identify the most influential features (for example, the top 15), and visualize them as a horizontal bar chart with clear axis labels and a readable title. Use matplotlib for all visualizations and keep the figures clean, interpretable, and suitable for instructional use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17a135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60ef9a4b",
   "metadata": {},
   "source": [
    "**Reflection prompt:** If your validation accuracy is much higher than test accuracy, what might be happening? How would you investigate it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0606eca",
   "metadata": {},
   "source": [
    "### Visualizing the Decision Tree\n",
    "\n",
    "Decision trees are popular because they are interpretable: you can literally see each split and explain predictions to teammates. Visualizing the trained tree helps confirm whether the splits match our intuition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780af586",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Visualize a Trained Decision Tree for the Titanic Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Visualize the structure of a trained decision tree classifier for the Titanic dataset. Assume a fitted `DecisionTreeClassifier` named `tree_model` already exists, along with a feature matrix `X`. Create a clear and readable visualization of the tree using scikit-learn’s tree plotting utilities, including feature names from `X` and class names labeled as “died (0)” and “survived (1)”. Use filled and rounded nodes, a readable font size, and an appropriate figure size to ensure the tree is easy to interpret. Add a descriptive title and adjust the layout so the visualization is suitable for teaching and discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93bd0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238a8cfc",
   "metadata": {},
   "source": [
    "## A Classic Dataset! (Iris Dataset)\n",
    "\n",
    "To build confidence, let’s repeat the same workflow on the classic Iris flower dataset included in scikit-learn. The steps—split, train, validate, test—stay the same regardless of dataset size.\n",
    "The Iris dataset is a classic multivariate dataset containing **150 iris flowers** from **three species**:\n",
    "\n",
    "- _setosa_ (label `0`)\n",
    "- _versicolor_ (label `1`)\n",
    "- _virginica_ (label `2`)\n",
    "\n",
    "Each row corresponds to a **single flower** and includes **four numeric features** (all in centimeters):\n",
    "\n",
    "- `sepal length (cm)`\n",
    "- `sepal width (cm)`\n",
    "- `petal length (cm)`\n",
    "- `petal width (cm)`\n",
    "\n",
    "In scikit-learn, the dataset is provided as a `Bunch` object with:\n",
    "\n",
    "- `data`: a `(150, 4)` feature matrix (`X_iris`)\n",
    "- `target`: a length‑150 vector of integer labels (`y_iris`)\n",
    "- `feature_names`: list of the four feature names\n",
    "- `target_names`: array mapping `0, 1, 2` → `\"setosa\"`, `\"versicolor\"`, `\"virginica\"`\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Built a **scatter-matrix** (`fig`) to visualize how the three species separate across pairs of features.\n",
    "- Split the data into **train**, **validation**, and **test** sets (`X_train_i`, `X_val_i`, `X_test_i`, etc.).\n",
    "- Trained a **DecisionTreeClassifier** (`iris_tree`) and evaluated it with accuracy on each split.\n",
    "- Computed a **confusion matrix** (`iris_cm`) to see how well the model distinguishes the three species; the current tree achieves **near-perfect (in our run, perfect) accuracy** on the test set.\n",
    "\n",
    "Because it is small, clean, and well-behaved (no missing values, balanced classes, simple numeric features), the Iris dataset is ideal for practicing supervised learning workflows: **split → train → validate → test**, interpreting decision trees, and comparing different classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e9125",
   "metadata": {},
   "source": [
    "![Iris Flowers Feature illustration](../../files/iris-flowers.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68900238",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Explore Feature Relationships in the Iris Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Create an interactive visualization to explore relationships between features in the Iris dataset. Load the Iris dataset using scikit-learn and assume access to both the feature data `X_iris` and target labels `y_iris`. Construct a pandas DataFrame that includes the feature values and a human-readable species label mapped from the target indices. Use Plotly Express to generate a scatter matrix showing pairwise relationships between all numeric features, color-coded by species. Customize the plot with a clear title, clean axis labels (removing units such as “(cm)” where appropriate), and hide the diagonal plots to reduce clutter. Ensure the visualization is interactive, readable, and suitable for instructional exploration of multivariate data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2769cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a10120",
   "metadata": {},
   "source": [
    "## Data Preprocessing (and why it matters)\n",
    "\n",
    "Before training a model, we often **preprocess** the data so the learning algorithm gets clean, consistent inputs.\n",
    "\n",
    "Common preprocessing steps:\n",
    "\n",
    "1. **Select features + label** (define what $X$ and $y$ are).\n",
    "2. **Fix data types** (e.g., strings → numbers when appropriate).\n",
    "3. **Handle missing values** (impute or drop).\n",
    "4. **Encode categorical variables** (e.g., one-hot encoding).\n",
    "5. **Scale/standardize numeric features** (important for many models).\n",
    "6. **Split into train/validation/test** without leakage.\n",
    "\n",
    "**Important note:** Decision trees usually _do not require_ feature scaling, but models like **logistic regression**, **SVMs**, and **k-NN** often do. Using a `Pipeline` keeps preprocessing and modeling bundled together correctly (and helps prevent leakage).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9039c13",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Create a Min–Max Scaled Scatter Matrix for the Iris Dataset\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Build an interactive scatter-matrix visualization of the Iris dataset after applying min–max scaling. Assume the Iris dataset has already been loaded and that `X_iris` contains the feature DataFrame and `y_iris` contains the target labels. Use `MinMaxScaler` to scale all numeric features, then convert the scaled output back into a pandas DataFrame with the original column names. Add a human-readable `species` column by mapping each target value to the corresponding name in `iris.target_names`. Clean up feature names for display by removing units in parentheses (such as “(cm)”) and formatting words to look like proper titles (e.g., “Sepal Length”, “Petal Width”). Use Plotly Express to create a scatter matrix of the scaled features, color points by species, hide the diagonal panels to reduce clutter, and apply simple layout tweaks (centered title, clear legend title, and a selection-friendly drag mode) so the visualization is clean, interactive, and suitable for teaching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd24a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66dc9033",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Train and Evaluate a Decision Tree on Scaled Iris Features\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Train and evaluate a small decision tree classifier called `iris_tree` on the Iris dataset using scaled features from earlier cells. Assume the Iris dataset has already been loaded, with scaled features available as `df_scaled` and labels available as `y_iris`. Perform a stratified train/validation/test split by holding out 30% of the data and then splitting that holdout evenly into validation and test sets, using a fixed `random_state` for reproducibility. Train a `DecisionTreeClassifier` with a fixed `random_state` and a limited maximum depth (such as 3), compute accuracy on the train, validation, and test splits using `accuracy_score`, and display the results in a small pandas DataFrame. Finally, print a test-set `classification_report` with human-readable class names from the Iris dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d8963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c46a7dde",
   "metadata": {},
   "source": [
    "### ✏️ Exercise: Visualize Iris Decision Tree Results\n",
    "\n",
    "#### **Prompt:**\n",
    "\n",
    "Visualize the results of a trained decision tree classifier on the Iris dataset using three complementary plots: a confusion matrix, the trained tree structure, and feature importances. Assume a fitted model named `iris_tree` already exists, along with the test split `X_test` and `y_test`. Extract the feature names from the DataFrame. First, generate test-set predictions and plot a confusion matrix using scikit-learn with class labels from `iris.target_names`, formatted as integer counts and styled with a blue color map and a clear title. Next, plot the trained decision tree using `sklearn.tree.plot_tree`, using cleaned feature names (for example, removing units like “(cm)”), and include readable class names, filled and rounded nodes, and a figure size that makes the tree easy to interpret. Finally, compute and plot the model’s feature importances as a horizontal bar chart showing the most influential features (for example, the top 10), with clear axis labels and a descriptive title. Use matplotlib for all visualizations and keep the plots clean, readable, and suitable for teaching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae105b0",
   "metadata": {},
   "source": [
    "### Lesson Summary: Supervised Machine Learning\n",
    "\n",
    "In this lesson, you were introduced to the fundamental ideas behind **supervised machine learning**, where models learn a mapping from input features to known output labels using labeled examples.\n",
    "\n",
    "A central theme throughout the lesson was **generalization**. You saw that a model’s goal is not to memorize the training data, but to perform well on **unseen data**. By using train–test splits and comparing models of varying complexity, you examined the concepts of **underfitting**, **overfitting**, and how model complexity influences performance.\n",
    "\n",
    "Overall, this lesson emphasized that supervised machine learning is a **design process**, not just an algorithm. Effective models require thoughtful data preparation, appropriate model selection, careful evaluation, and clear interpretation of results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
