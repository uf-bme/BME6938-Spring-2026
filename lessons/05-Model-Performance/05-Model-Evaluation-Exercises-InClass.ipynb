{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98be42c8",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation - In-Class Exercises\n",
    "\n",
    "In this notebook, you will practice evaluating supervised learning models using proper train-test splitting strategies, computing various evaluation metrics, and performing cross-validation with confidence intervals.\n",
    "\n",
    "**Datasets:**\n",
    "- **Titanic**: Binary classification (Survived: 0 or 1) - imbalanced dataset\n",
    "- **Iris**: Multiclass classification (3 species) - balanced dataset\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Implement proper train-test splitting strategies\n",
    "- Compute and interpret evaluation metrics for binary and multiclass problems\n",
    "- Calculate ROC curves\n",
    "- Perform cross-validation with confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5f869",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries\n",
    "\n",
    "All necessary imports are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf723bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c28351",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Binary Classification - Titanic Dataset\n",
    "\n",
    "### Dataset Loading and Preprocessing\n",
    "\n",
    "The code below loads and preprocesses the Titanic dataset. This is provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Display first few rows and info\n",
    "print(\"Dataset shape:\", titanic.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(titanic.head())\n",
    "print(\"\\nMissing values:\")\n",
    "print(titanic.isnull().sum())\n",
    "print(\"\\nClass distribution:\")\n",
    "print(titanic['survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39982f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Select features and handle missing values\n",
    "# Select relevant features\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "target = 'survived'\n",
    "\n",
    "# Create a copy with selected features\n",
    "df_titanic = titanic[features + [target]].copy()\n",
    "\n",
    "# Handle missing values\n",
    "# Fill missing age with median\n",
    "df_titanic['age'] = df_titanic['age'].fillna(df_titanic['age'].median())\n",
    "\n",
    "# Fill missing embarked with mode\n",
    "df_titanic['embarked'] = df_titanic['embarked'].fillna(df_titanic['embarked'].mode()[0])\n",
    "\n",
    "# Fill missing fare with median\n",
    "df_titanic['fare'] = df_titanic['fare'].fillna(df_titanic['fare'].median())\n",
    "\n",
    "# Encode categorical variables\n",
    "df_titanic['sex'] = df_titanic['sex'].map({'male': 0, 'female': 1})\n",
    "df_titanic = pd.get_dummies(df_titanic, columns=['embarked'], prefix='embarked', drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X_titanic = df_titanic.drop(target, axis=1)\n",
    "y_titanic = df_titanic[target]\n",
    "\n",
    "print(\"Preprocessed dataset shape:\", X_titanic.shape)\n",
    "print(\"Features:\", list(X_titanic.columns))\n",
    "print(\"\\nNo missing values remaining:\", X_titanic.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cfc5c",
   "metadata": {},
   "source": [
    "---\n",
    "## ✏️ Exercise 1: Train-Test Split with Stratification\n",
    "\n",
    "**Task:** Create a train-test split for the Titanic dataset.\n",
    "\n",
    "**Requirements:**\n",
    "- Use 70% of the data for training and 30% for testing\n",
    "- Set `random_state=42` for reproducibility\n",
    "- Store the results in variables: `X_train_titanic`, `X_test_titanic`, `y_train_titanic`, `y_test_titanic`\n",
    "\n",
    "*Tip: For imbalanced datasets like Titanic, consider whether you want the same class distribution in both train and test sets. Check the `stratify` parameter in the documentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54144e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STUDENT CODE START =====\n",
    "\n",
    "# ===== STUDENT CODE END ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacab44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the split by checking shapes and class distributions\n",
    "print(\"Train set shape:\", X_train_titanic.shape)\n",
    "print(\"Test set shape:\", X_test_titanic.shape)\n",
    "print(\"\\nTrain set class distribution:\")\n",
    "print(y_train_titanic.value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test_titanic.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed1484",
   "metadata": {},
   "source": [
    "### Model Training Code \n",
    "\n",
    "Below is the model training code. **Warning** - you will need to create the train-test split first in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe88b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "# This cell should be run AFTER you complete Exercise 1\n",
    "\n",
    "model_titanic = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_titanic.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_titanic = model_titanic.predict(X_test_titanic)\n",
    "y_pred_proba_titanic = model_titanic.predict_proba(X_test_titanic)[:, 1]\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5579a6",
   "metadata": {},
   "source": [
    "---\n",
    "## ✏️ Exercise 2: Binary Classification Evaluation Metrics\n",
    "\n",
    "**Task:** Calculate the following evaluation metrics for the Titanic model:\n",
    "1. Confusion Matrix\n",
    "2. Accuracy\n",
    "3. Precision\n",
    "4. Recall\n",
    "5. F1-Score\n",
    "6. ROC-AUC Score\n",
    "\n",
    "**Visualization Requirements:**\n",
    "- Create a heatmap visualization of the confusion matrix using seaborn\n",
    "- Plot the ROC curve with AUC score using matplotlib\n",
    "\n",
    "*Tip: All these functions are available in `sklearn.metrics`. For ROC-AUC, you'll need predicted probabilities, not just class predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1965dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STUDENT CODE START =====\n",
    "\n",
    "# ===== STUDENT CODE END =====\n",
    "\n",
    "# Print results\n",
    "print(\"=\"*60)\n",
    "print(\"TITANIC DATASET - Binary Classification Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_titanic)\n",
    "print(f\"\\nAccuracy: {accuracy_titanic:.4f}\")\n",
    "print(f\"Precision: {precision_titanic:.4f}\")\n",
    "print(f\"Recall: {recall_titanic:.4f}\")\n",
    "print(f\"F1-Score: {f1_titanic:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_titanic:.4f}\")\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap and ROC Curve\n",
    "# ===== STUDENT CODE START =====\n",
    "\n",
    "# ===== STUDENT CODE END =====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061ae13",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Multiclass Classification - Iris Dataset\n",
    "\n",
    "### Dataset Loading\n",
    "\n",
    "The Iris dataset is balanced and clean, requiring minimal preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_iris = iris.target\n",
    "\n",
    "print(\"Dataset shape:\", X_iris.shape)\n",
    "print(\"Target classes:\", iris.target_names)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(pd.Series(y_iris).value_counts().sort_index())\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(X_iris.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Statistics (Before Scaling)\")\n",
    "print(\"=\"*60)\n",
    "display(X_iris.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Feature Scaling\n",
    "# Many sklearn models (e.g., Logistic Regression, SVM, KNN) benefit from scaled features\n",
    "# StandardScaler standardizes features by removing the mean and scaling to unit variance\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_iris_scaled = scaler.fit_transform(X_iris)\n",
    "X_iris = pd.DataFrame(X_iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Feature Statistics (After Scaling)\")\n",
    "print(\"=\"*60)\n",
    "display(X_iris.describe())\n",
    "print(\"\\nFeatures are now scaled with mean ≈ 0 and std ≈ 1\")\n",
    "print(\"This improves performance for distance-based and gradient-based models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d267697",
   "metadata": {},
   "source": [
    "---\n",
    "## ✏️ Exercise 3: Train-Test Split for Balanced Dataset\n",
    "\n",
    "**Task:** Create a train-test split for the Iris dataset.\n",
    "\n",
    "**Requirements:**\n",
    "- Use 70% of the data for training and 30% for testing\n",
    "- Set `random_state=42` for reproducibility\n",
    "- Store the results in variables: `X_train_iris`, `X_test_iris`, `y_train_iris`, `y_test_iris`\n",
    "\n",
    "*Note: Since Iris is a balanced dataset, stratification is optional but still good practice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STUDENT CODE START =====\n",
    "\n",
    "# ===== STUDENT CODE END ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace80d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the split\n",
    "print(\"Train set shape:\", X_train_iris.shape)\n",
    "print(\"Test set shape:\", X_test_iris.shape)\n",
    "print(\"\\nTrain set class distribution:\")\n",
    "print(pd.Series(y_train_iris).value_counts().sort_index())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test_iris).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6bcc89",
   "metadata": {},
   "source": [
    "### Model Training Code\n",
    "\n",
    "Below is the model training code. **Warning** - complete Exercise 3 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ff07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model for multiclass classification\n",
    "# This cell should be run AFTER you complete Exercise 3\n",
    "\n",
    "model_iris = LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr')\n",
    "model_iris.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_iris = model_iris.predict(X_test_iris)\n",
    "y_pred_proba_iris = model_iris.predict_proba(X_test_iris)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Training set size: {len(X_train_iris)}\")\n",
    "print(f\"Test set size: {len(X_test_iris)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707eb1b6",
   "metadata": {},
   "source": [
    "---\n",
    "## ✏️ Exercise 4: Multiclass Classification Evaluation Metrics\n",
    "\n",
    "**Task:** Calculate the following evaluation metrics for the Iris model:\n",
    "1. Confusion Matrix\n",
    "2. Overall Accuracy\n",
    "3. Precision (macro, micro, and weighted averages)\n",
    "4. Recall (macro, micro, and weighted averages)\n",
    "5. F1-Score (macro, micro, and weighted averages)\n",
    "\n",
    "**Visualization Requirement:**\n",
    "- Create a heatmap visualization of the confusion matrix using seaborn with proper class labels\n",
    "\n",
    "*Tip: For multiclass metrics, check the `average` parameter. Different averaging methods give you different perspectives on model performance.*\n",
    "\n",
    "**'macro':** (Default in many functions): Calculates the metric for each label and finds their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "**'weighted':** Calculates the metric for each label and finds their average, weighted by support (the number of true instances for each label). This accounts for label imbalance.\n",
    "\n",
    "**'micro':** Calculates metrics globally by counting the total true positives, false negatives, and false positives.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== STUDENT CODE START =====\n",
    "# ===== END CODE START =====\n",
    "\n",
    "# Print results\n",
    "print(\"=\"*60)\n",
    "print(\"IRIS DATASET - Multiclass Classification Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_iris)\n",
    "print(f\"\\nOverall Accuracy: {accuracy_iris:.4f}\")\n",
    "print(\"\\nPrecision:\")\n",
    "print(f\"  Macro:    {precision_macro_iris:.4f}\")\n",
    "print(f\"  Micro:    {precision_micro_iris:.4f}\")\n",
    "print(f\"  Weighted: {precision_weighted_iris:.4f}\")\n",
    "print(\"\\nRecall:\")\n",
    "print(f\"  Macro:    {recall_macro_iris:.4f}\")\n",
    "print(f\"  Micro:    {recall_micro_iris:.4f}\")\n",
    "print(f\"  Weighted: {recall_weighted_iris:.4f}\")\n",
    "print(\"\\nF1-Score:\")\n",
    "print(f\"  Macro:    {f1_macro_iris:.4f}\")\n",
    "print(f\"  Micro:    {f1_micro_iris:.4f}\")\n",
    "print(f\"  Weighted: {f1_weighted_iris:.4f}\")\n",
    "\n",
    "# Visualize Confusion Matrix \n",
    "\n",
    "\n",
    "# ===== STUDENT CODE START =====\n",
    "# ===== END CODE START =====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89322bb4",
   "metadata": {},
   "source": [
    "---\n",
    "## ✏️ Part 3: Cross-Validation with Confidence Intervals\n",
    "\n",
    "### Exercise 5: K-Fold Cross-Validation with Confidence Intervals\n",
    "\n",
    "**Task:** Perform stratified k-fold cross-validation on both datasets and calculate 95% confidence intervals for the F1-scores.\n",
    "\n",
    "**Requirements:**\n",
    "1. Use 5-fold stratified cross-validation\n",
    "2. Calculate cross-validation F1-scores for both Titanic and Iris datasets\n",
    "3. For each dataset, compute:\n",
    "   - Mean F1-score\n",
    "   - Standard deviation\n",
    "   - 95% confidence interval using the t-distribution\n",
    "\n",
    "*Tip: Cross-validation returns an array of scores (one per fold). The standard error (SE) is calculated as std/sqrt(n) where n is the number of folds. For a 95% confidence interval with a t-distribution, you'll need the degrees of freedom (n-1). Consider using `scipy.stats.t.interval()`. For F1-score with binary classification, use `scoring='f1'`. For multiclass, use `scoring='f1_macro'`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f01123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STUDENT CODE START =====\n",
    "\n",
    "# ===== STUDENT CODE END ====="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
